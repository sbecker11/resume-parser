{
  "contactInformation": {
    "name": "SHAWN BECKER",
    "location": "Lehi, UT",
    "phone": "(857) 891-0896",
    "email": "sbecker@alum.mit.edu"
  },
  "position": "DATA ENGINEERING / DATA ARCHITECTURE / MACHINE LEARNING",
  "professionalSummary": "As an experienced data engineering professional with expertise in Data Architecture and Machine Learning, I excel in problem-solving and leading teams to deliver innovative solutions to complex challenges across diverse industries, including entertainment, healthcare, finance, and manufacturing. My expertise includes creating scalable, secure, high-volume data pipelines leveraging cloud infrastructure and domain-specific data architecture while employing machine learning models to optimize data-driven decision-making processes. I thrive in dynamic environments, applying Agile methodologies to facilitate my team's focus on building working increments of well-architecture solutions that meet product owners' expectations. Driven by a passion for continuous learning, I relish tackling new challenges and achieving excellence in every project.",
  "workExperience": [
    {
      "company": "Fannie Mae / Risk Works Analysis Data Lake",
      "location": "Remote",
      "duration": {
        "start": "Mar 2024",
        "end": "Jun 2024"
      },
      "position": "Senior Data Engineer",
      "responsibilities": [
        "Documented processes to build, test, and deploy data pipeline components for in-house ETL framework.",
        "Extensive work with SQL, AWS Redshift, Glue, S3, IAM, Lambda, REST, Postman, SNS, and dbt.",
        "Utilized Agile practices with Jira, including backlog refinements, sprint planning, daily scrums, bi-weekly sprint reviews, and end-of-sprint retrospectives. Enabled the product owner to review each shipped product increment, allowing for potential revision or re-prioritization of backlog items."
      ]
    },
    {
      "company": "The Cigna Group / Data Cybersecurity",
      "location": "Remote",
      "duration": {
        "start": "Jun 2023",
        "end": "Dec 2023"
      },
      "position": "Senior Data Engineer",
      "responsibilities": [
        "Modernized apps via Jenkins CI/CD pipeline upgrade, integrating SetupTools, Artifactory/PyPI, SonarQube, and Xray.",
        "Investigated and implemented preparation of legacy ETL data pipeline components. Migration from on-prem Unity IoC apps to the AWS cloud using CDC.",
        "Engineered Python REST API enabling credential retrieval from CyberArk's identity management platform using mutual TLS/SSL authentication via AWS API Gateway",
        "Initiated CyberArk service updates to extract credentials at runtime, avoiding the need to access locally encrypted files and eliminating engineering efforts to satisfy cybersecurity requirements. The cost was reduced by 95% of the original for each password rollover event."
      ]
    },
    {
      "company": "Warner Brothers Interactive Entertainment",
      "location": "Remote",
      "duration": {
        "start": "Sep 2022",
        "end": "Apr 2023"
      },
      "position": "Senior Data Engineer / Data Scientist",
      "responsibilities": [
        "Utilized PySpark for ETL processes and Python for third-party integrations and dev-ops collaborations with Jenkins, DataDog, and ZenDesk. I leveraged Google BigQuery and AWS services, including Lambda, Aurora PostgreSQL, SalesForce, Snowflake, and AWS Glue.",
        "Developed high-volume pipeline ingress and integrations, enabling efficient game telemetry and user PII data transfer between WB-distributed games and leading marketing platforms using Segment CDP, Kafka, Redshift, Glue, and Airflow for orchestration.",
        "Conducted exploration and statistical analysis of marketing data, including principal component analysis, eigenvector decomposition, dimensionality reduction, vectorization, Bayesian clustering, and collaborative filtering. I used Jupyter, Python, Pandas, NumPy, Sci-kit Learn, and Keras for analytical processing and Seaborn, Plotly, and Matplotlib for data visualization.",
        "Practiced Agile SDLC in Jira with spring planning, daily scrums, and bi-weekly sprint reviews."
      ]
    },
    {
      "company": "Angel Studios",
      "location": "Provo, Utah",
      "duration": {
        "start": "Dec 2021",
        "end": "Aug 2022"
      },
      "position": "Data Scientist",
      "responsibilities": [
        "Used AWS SageMaker, Python, and Machine Learning packages, Pytorch and Keras, to build and optimize a supervised CNN for classifying movie frames from episodes stored in S3.",
        "Earned certifications in Advanced Learning Algorithms, Advanced SQL for Data Scientists, and Supervised Machine Learning: Regression & Classification, boosting professional skills.",
        "Conducted data exploration with machine learning algorithms using Jupyter, Python, Pandas, NumPy, Sci-kit Learn, and Keras for processing, and Seaborn, Plotly, and Matplotlib for data visualization to enhance analytical capabilities significantly.",
        "Developed effective Business Intelligence strategies using Looker and Tableau with Snowflake and Redshift for comprehensive sales and finance reporting."
      ]
    },
    {
      "company": "Greenseed Data Laboratory",
      "location": "Orem, Utah",
      "duration": {
        "start": "Nov 2020",
        "end": "Nov 2021"
      },
      "position": "Senior Data Engineer Data Scientist",
      "responsibilities": [
        "Conducted advanced statistical exploration of real-estate sales data using Python, Pandas, NumPy, SciPy, and Scikit-learn.",
        "Implemented a CI/CD pipeline using GitHub Actions with Coverage, SonarQube, and Xray",
        "Designed and built a custom star-schema data warehouse on PostgreSQL, using dimensional modeling, featuring SCD type-2 tables sharing a common streaming facts table.",
        "Enhanced machine learning skills with tutorials for TensorFlow, PyTorch, and Keras using Kaggle datasets."
      ]
    },
    {
      "company": "NuSkin",
      "location": "Provo, Utah",
      "duration": {
        "start": "Nov 2019",
        "end": "Nov 2020"
      },
      "position": "Senior Full Stack Developer",
      "responsibilities": [
        "Enhanced site registration and login pages by designing workflow and wireframes.",
        "Innovated Vue Vuetify components with NodeJS SCSS for improved functionality.",
        "Documented and launched new packages for company-wide use, enhancing efficiency.",
        "Internationalized content using Adobe Experience Cloud."
      ]
    },
    {
      "company": "SeniorLink / Vela",
      "location": "Boston, MA",
      "duration": {
        "start": "Mar 2017",
        "end": "Nov 2019"
      },
      "position": "Senior Data Engineer",
      "responsibilities": [
        "Designed and deployed an AWS data pipeline for the Vela platform, which provided messaging, communication, and collaboration tools for the healthcare industry.",
        "Managed data ingress by queueing API Gateway-delivered message payloads into Amazon Kinesis Data Stream shards. Utilized SNS-triggered Python jobs running on serverless Lambdas to aggregate shard data into date-partitioned Parquet files in an S3 data lake.",
        "Performed ETL processes, extracting, transforming, and loading Parquet data from the data lake to Redshift via scheduled PySpark batch jobs on an EMR cluster orchestrated by Data Pipeline.",
        "Generated daily business intelligence reports using Tableau with Redshift OLAP.",
        "Coordinated with domestic and offshore development and quality assurance teams."
      ]
    },
    {
      "company": "ClipFile",
      "location": "Newton Center, MA",
      "duration": {
        "start": "Feb 2011",
        "end": "Mar 2017"
      },
      "position": "Technical Project Manager, Solutions Architect, Co-Founder",
      "responsibilities": [
        "Led a team to develop and launch a pioneering SaaS on the AWS platform, empowering individuals and content creators to search and share curated mindsets.",
        "Designed and implemented patented technology, creating a consumer-facing CMS that facilitated fuzzy matching among user-curated quotes and text fragments.",
        "Applied machine learning algorithms including principal component analysis, eigenvector decomposition, dimensionality reduction, vectorization, cosine similarities, K-means, Bayesian clustering, and collaborative filtering to implement fuzzy word matching and word clustering.",
        "Utilized a RESTful API interface for the in-app presentation layer and as a service interface for external client apps."
      ]
    },
    {
      "company": "Sierra Vista Group",
      "location": "Boston, MA",
      "duration": {
        "start": "Nov 2002",
        "end": "Feb 2011"
      },
      "position": "Technical Program Manager, Solutions Architect / Co-Founder",
      "responsibilities": [
        "Identified profitable opportunities in product development, software engineering, and data modeling and successfully negotiated budgets and project milestones with C-level management.",
        "Recruited high-value independent consultants specializing in DevOps, full-stack development, database administration, graphic design, user experience, and quality assurance.",
        "Developed and aligned comprehensive project schedules and detailed technical specifications with specific business requirements within strict budgets using the Waterfall SDLC process.",
        "Mitigated schedule and budget issues with client-management when required.",
        "Managed IT strategies customized for clients in the entertainment, medical services, manufacturing, insurance, and cyber security industries, including AMI, Rowe Jukeboxes, Eleven Systems, Coca-Cola Corp. Europe, Medical Services Corp., and Intrusic Cyber Security."
      ]
    }
  ],
  "education": [
    {
      "institution": "Massachusetts Institute of Technology, Cambridge, Massachusetts",
      "degree": "PhD, Media Arts & Sciences, Machine Vision/Video Coding"
    },
    {
      "institution": "Brigham Young University, Provo, Utah",
      "degree": "MS, Computer Science, Medical Imaging/Computer Graphics"
    },
    {
      "institution": "Brigham Young University, Provo, Utah",
      "degree": "BS, Design Engineering Technology, CAD/CAE/CAM"
    }
  ],
  "skills": [
    "AWS Architecture",
    "Amazon S3",
    "DBT",
    "Glue",
    "Glue Catalog",
    "Lambdas",
    "Step Functions",
    "Kinesis Data Streams",
    "Kafka",
    "SQS",
    "SNS",
    "SMS",
    "EC2",
    "Redshift",
    "DynamoDB",
    "SimpleDB",
    "ElastiCache",
    "Aurora",
    "Snowflake",
    "Looker",
    "Tableau",
    "Databricks Medallion Architecture",
    "Delta Lake",
    "Databricks Lakehouse",
    "CloudFormation",
    "Docker",
    "Kubernetes",
    "ECR",
    "ECS",
    "EKS",
    "Fargate",
    "Data Pipeline",
    "PySpark",
    "EMR",
    "AWS Migration Service",
    "SQL",
    "Python",
    "Java",
    "Airflow",
    "Amazon QuickSight",
    "Git",
    "REST API",
    "CI/CD",
    "Jenkins",
    "GitHub Actions",
    "Unit Testing",
    "Integration Testing",
    "SageMaker",
    "GitHub",
    "Bitbucket",
    "PostgreSQL",
    "Oracle",
    "MS SQL Server",
    "Machine Learning",
    "Regression",
    "Classification",
    "CNN",
    "Clustering",
    "Dimensionality Reduction",
    "PCA",
    "RAG",
    "Encoding",
    "MSProject",
    "Visio",
    "Office 365",
    "Agile Scrum SDLC",
    "Scheduling",
    "Budgets",
    "Milestones",
    "Risk Mitigation",
    "Stakeholder Management",
    "Resource Allocation",
    "Leadership",
    "Tutoring",
    "Team Building",
    "Offshore Management",
    "Cybersecurity",
    "DataDog",
    "CloudWatch",
    "Confluence",
    "Jira",
    "Certified Scrum Master\u00a9"
  ],
  "certifications": "https://www.linkedin.com/in/shawnbecker/details/certifications/",
  "publications": "https://independent.academia.edu/shawnbecker",
  "patents": "https://patents.justia.com/inventor/shawn-c-becker",
  "websites": [
    "https://www.linkedin.com/in/shawnbecker",
    "http://spexture.com"
  ]
}