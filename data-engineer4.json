{
  "contactInformation": "SHAWN BECKER\nLehi, UT \u2022 (857) 891-0896 \u2022 sbecker@alum.mit.edu",
  "positionOrProfessionalTitle": "DATA ENGINEERING / DATA ARCHITECTURE / MACHINE LEARNING",
  "professionalSummary": "As an experienced data engineering professional with expertise in Data Architecture and Machine Learning, I\nexcel in problem-solving and leading teams to deliver innovative AWS-based solutions to complex challenges\nacross diverse industries, including entertainment, healthcare, finance, and manufacturing. My expertise\nincludes creating scalable, secure, high-volume data pipelines, and low-bandwidth IoT systems leveraging\ncloud infrastructure and domain-specific data architecture while employing machine learning models to optimize\ndata-driven decision-making processes. I thrive in dynamic environments, applying Agile methodologies to\nfacilitate my team's focus on building working increments of well-architected solutions that meet product owners'\nexpectations. Driven by a passion for continuous learning, I relish tackling new challenges and achieving\nexcellence in every project.",
  "workExperience": [
    {
      "companyName": "Fannie Mae / Risk Works Analysis Data Lake",
      "location": "Remote",
      "duration": {
        "start": "Mar 2024",
        "end": "Jun 2024"
      },
      "positionOrTitle": "Senior Data Engineer",
      "responsibilities": [
        "Documented processes to build, test, and deploy data pipeline components for in-house ETL framework",
        "Extensive work with SQL, AWS Redshift, Glue, S3, IAM, Lambda, REST, Postman, SNS, and dbt",
        "Utilized Agile practices with Jira, including backlog refinements, sprint planning, daily scrums, bi-weekly\nsprint reviews, and end-of-sprint retrospectives. Enabled the product owner to review each shipped\nproduct increment, allowing for potential revision or re-prioritization of backlog items"
      ]
    },
    {
      "companyName": "The Cigna Group / Data Cybersecurity",
      "location": "Remote",
      "duration": {
        "start": "Jun 2023",
        "end": "Dec 2023"
      },
      "positionOrTitle": "Senior Data Engineer",
      "responsibilities": [
        "Modernized apps via Jenkins CI/CD pipeline upgrade, integrating SetupTools, Artifactory/PyPI,\nSonarQube, and Xray",
        "Investigated and implemented preparation of legacy ETL data pipeline components. Migration from on-\nprem Unity IoC apps to the AWS cloud using CDC",
        "Ensured privacy and encryption standards for user data",
        "Engineered Python REST API integration enabling credential retrieval from CyberArk's identity\nmanagement platform using mutual TLS/SSL authentication via AWS API Gateway",
        "Initiated CyberArk service updates to extract credentials at runtime, avoiding the need to access locally\nencrypted files and eliminating engineering efforts to satisfy cybersecurity requirements. The cost was\nreduced by 95% of the original for each password rollover event"
      ]
    },
    {
      "companyName": "Warner Brothers Interactive Entertainment",
      "location": "Remote",
      "duration": {
        "start": "Sep 2022",
        "end": "Apr 2023"
      },
      "positionOrTitle": "Senior Data Engineer",
      "responsibilities": [
        "Utilized PySpark for ETL processes and Python for third-party integrations and dev-ops collaborations\nwith Jenkins, DataDog, and ZenDesk. I leveraged Google BigQuery and AWS services, including\nLambda, Aurora PostgreSQL, SalesForce, Sno, and AWS Glue",
        "Developed high-volume pipeline ingress and RESTful API integrations, enabling efficient game telemetry\nand user PII data transfer between WB-distributed games and leading marketing platforms using\nSegment CDP, Kafka, Redshift, Glue, and Airflow for orchestration",
        "Conducted exploration and statistical analysis of marketing data, including principal component analysis,\neigenvector decomposition, dimensionality reduction, vectorization, Bayesian clustering, and\ncollaborative filtering. I used Jupyter, Python, Pandas, NumPy, Sci-kit Learn, and Keras for analytical\nprocessing and Seaborn, Plotly, and Matplotlib for data visualization",
        "Practiced Agile SDLC in Jira with spring planning, daily scrums, and bi-weekly sprint reviews"
      ]
    },
    {
      "companyName": "Angel Studios",
      "location": "Provo, Utah",
      "duration": {
        "start": "Dec 2021",
        "end": "Aug 2022"
      },
      "positionOrTitle": "Senior Data Engineer",
      "responsibilities": [
        "Used AWS SageMaker, Python, and Machine Learning packages, Pytorch and Keras, to build and\noptimize a supervised CNN for classifying movie frames from episodes stored in S3",
        "Earned certifications in Advanced Learning Algorithms, Advanced SQL for Data Scientists, and\nSupervised Machine Learning: Regression & Classification, boosting professional skills",
        "Conducted data exploration with machine learning algorithms using Jupyter, Python, Pandas, NumPy,\nSci-kit Learn, and Keras for processing, and Seaborn, Plotly, and Matplotlib for data visualization to\nenhance analytical capabilities significantly",
        "Created RESTful APIs to exchange data with external e-commerce and advertising partners",
        "Created Snowflake ingestion scripts to support Looker business intelligence reporting",
        "Developed effective Business Intelligence strategies using Looker and Tableau with Snowflake and\nRedshift for comprehensive sales and finance reporting"
      ]
    },
    {
      "companyName": "Greenseed Data Laboratory",
      "location": "Orem, Utah",
      "duration": {
        "start": "Nov 2020",
        "end": "Nov 2021"
      },
      "positionOrTitle": "Senior Data Engineer",
      "responsibilities": [
        "Conducted advanced statistical exploration of real-estate sales data using Python, Pandas, NumPy,\nSciPy, and Scikit-learn",
        "Implemented a CI/CD pipeline using GitHub Actions with Coverage, SonarQube, and Xray",
        "Designed and built a custom star-schema data warehouse on PostgreSQL, using dimensional modeling,\nfeaturing SCD type-2 tables sharing a common streaming facts table",
        "Managed RESTful APIs used to exchange data with real-estate data teams and customers",
        "Enhanced machine learning skills with tutorials for TensorFlow, PyTorch, and Keras using Kaggle\ndatasets"
      ]
    },
    {
      "companyName": "NuSkin",
      "location": "Provo, Utah",
      "duration": {
        "start": "Nov 2019",
        "end": "Nov 2020"
      },
      "positionOrTitle": "Senior Full Stack Developer",
      "responsibilities": [
        "Enhanced site registration and login pages by designing workflow and wireframes",
        "Innovated Vue Vuetify components with NodeJS SCSS for improved functionality",
        "Documented and launched new packages for company-wide use, enhancing efficiency",
        "Internationalized content using Adobe Experience Cloud"
      ]
    },
    {
      "companyName": "SeniorLink / Vela",
      "location": "Boston, MA",
      "duration": {
        "start": "Mar 2017",
        "end": "Nov 2019"
      },
      "positionOrTitle": "Senior Data Engineer",
      "responsibilities": [
        "Designed and deployed an AWS data pipeline for the Vela platform, which provided messaging,\ncommunication, and collaboration tools for the healthcare industry",
        "Defined RESTful APIs used by client web applications for posting daily questionnaire forms",
        "Managed data ingress by queueing API Gateway-delivered message payloads into Amazon Kinesis\nData Stream shards. Utilized SNS-triggered Python jobs running on serverless Lambdas to aggregate\nshard data into date-partitioned Parquet files in an S3 data lake",
        "for Performed ETL processes, extracting, transforming, and loading Parquet data from the data lake to\nRedshift via scheduled Databricks PySpark batch jobs on an EMR cluster orchestrated by Data Pipeline",
        "Ensured privacy and encryption standards for PII, PHI, PCI, Patient Data, FHIR, and HL7, as well as\nHIPAA and GDPR compliance",
        "Generated daily business intelligence reports using Tableau with Redshift OLAP"
      ]
    },
    {
      "companyName": "ClipFile",
      "location": "Newton Center, MA",
      "duration": {
        "start": "Feb 2011",
        "end": "Mar 2017"
      },
      "positionOrTitle": "Technical Lead, Co-Founder",
      "responsibilities": [
        "Led a team to develop and launch a pioneering SaaS on the AWS platform, empowering individuals and\ncontent creators to search and share curated mindsets",
        "Designed and implemented patented technology, creating a consumer-facing CMS that facilitated fuzzy\nmatching among user-curated quotes and text fragments",
        "Applied machine learning algorithms, including principal component analysis, eigenvector\ndecomposition, dimensionality reduction, vectorization, cosine similarities, K-means, Bayesian\nclustering, and collaborative filtering to implement fuzzy word matching and word clustering",
        "Defined and developed a RESTful API interface for the business logic layer used by the in-app\npresentation layer and as a service interface for external client apps"
      ]
    },
    {
      "companyName": "Sierra Vista Group",
      "location": "Boston, MA",
      "duration": {
        "start": "Nov 2002",
        "end": "Feb 2011"
      },
      "positionOrTitle": "Technical Lead, Co-Founder",
      "responsibilities": [
        "Identified profitable opportunities in product development, software engineering, and data modeling and\nsuccessfully negotiated budgets and project milestones with C-level management",
        "Recruited high-value independent consultants specializing in DevOps, full-stack development, database\nadministration, graphic design, user experience, and quality assurance",
        "Developed and aligned comprehensive project schedules and detailed technical specifications with\nspecific business requirements within strict budgets using the Waterfall SDLC process",
        "Ensured privacy and encryption standards for PII, PHI, PCI, Patient Data, FHIR, and HL7, as well as\nHIPAA and GDPR compliance",
        "Mitigated schedule and budget issues with client management when required",
        "Architected solutions using full-internet as well as low-bandwidth cache-and-sync IoT techniques for\nintermittent network environments in enterprise systems with mobile devices",
        "Managed IT strategies customized for clients in the entertainment, medical services, manufacturing,\ninsurance, and cyber security industries, including AMI, Rowe Jukeboxes, Eleven Systems, Coca-Cola\nCorp. Europe, Medical Services Corp., and Intrusic Cyber Security"
      ]
    }
  ],
  "education": [
    {
      "institution": "Massachusetts Institute of Technology, Cambridge, Massachusetts",
      "degree": "PhD, Media Arts & Sciences, Machine Vision/Video Coding"
    },
    {
      "institution": "Brigham Young University, Provo, Utah",
      "degree": "MS, Computer Science, Medical Imaging/Computer Graphics"
    },
    {
      "institution": "Brigham Young University, Provo, Utah",
      "degree": "BS, Design Engineering Technology, CAD/CAE/CAM"
    }
  ],
  "skills": "AWS Architecture \u2022 Amazon S3 \u2022 Amazon EC2 \u2022 Amazon VPC \u2022 Amazon ElastiCache \u2022 Amazon Aurora \u2022\nAmazon CloudFormation \u2022 Docker \u2022 Kubernetes \u2022 Amazon ECR \u2022 Amazon ECS \u2022 Amazon EKS \u2022 Amazon\nFargate \u2022 AWS Migration Service \u2022 DBT \u2022 Amazon Glue \u2022 Amazon Glue Catalog \u2022 Amazon Lambda \u2022 Amazon\nStep Functions \u2022 Kinesis Data Streams \u2022 Amazon SQS \u2022 Amazon SNS \u2022 Amazon Data Pipeline \u2022 Amazon EMR\n\u2022 Airflow \u2022 Databricks Medallion Architecture \u2022 Delta Lake \u2022 DataDog \u2022 New Relic \u2022 Amazon CloudWatch \u2022\nPostgreSQL \u2022 Amazon Redshift \u2022 Amazon DynamoDB \u2022 Amazon SimpleDB \u2022 Oracle \u2022 SQL Server \u2022 MongoDB\n\u2022 SQL \u2022 Python \u2022 PySpark \u2022 Java \u2022 Git \u2022 REST API \u2022 CI/CD \u2022 Jenkins \u2022 GitHub Actions \u2022 GitHub \u2022 Bitbucket \u2022\nLooker \u2022 Tableau \u2022 Amazon QuickSight \u2022 Amazon Sagemaker \u2022 Machine Learning \u2022 Regression \u2022 Classification\n\u2022 CNN \u2022 Clustering \u2022 Dimensionality Reduction \u2022 PCA \u2022 RAG \u2022 NLP \u2022 Encoding \u2022 Embedding \u2022 Cybersecurity \u2022\nCyberArk \u2022 PII \u2022 PHI \u2022 PCI \u2022 HIPAA \u2022 GDPR \u2022 Quality Assurance Testing \u2022 Patient Data \u2022 FHIR \u2022 HL7 \u2022 Agile\nScrum SDLC \u2022 MS Project \u2022 Visio \u2022 Office 365 \u2022 Scheduling \u2022 Budgets \u2022 Milestones \u2022 Risk Mitigation \u2022 Certified\nScrumMaster \u2022 Stakeholder Management \u2022 Confluence \u2022 Jira \u2022 Presentation Skills \u2022 Communication Skills \u2022\nWriting Skills \u2022 Resource Allocation \u2022 Leadership \u2022 Tutoring \u2022 Team Building \u2022 LangChain \u2022 NLP \u2022 Private\nGPT \u2022 NodeJS \u2022 Databricks \u2022 Snowflake",
  "certifications": "https://www.linkedin.com/in/shawnbecker/details/certifications/",
  "publications": "https://independent.academia.edu/shawnbecker",
  "patents": "https://patents.justia.com/inventor/shawn-c-becker",
  "websitesOrOnlineProfiles": [
    "https://www.linkedin.com/in/shawnbecker",
    "https://github.com/sbecker11"
  ],
  "currentWork": [
    {
      "name": "AI-Powered Resume Visualization Tool",
      "description": "Developing a novel 2.5D resume visualization application using\nLangChain and OpenAI's GPT models. This project involves PDF parsing, natural language processing, and\nfull-stack development with NodeJS.",
      "url": "http://spexture.com",
      "githubRepo": "https://github.com/sbecker11/flock-of-postcards"
    }
  ]
}